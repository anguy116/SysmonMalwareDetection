{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "27c794ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import functions as fn\n",
    "\n",
    "import os\n",
    "import random\n",
    "import itertools\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import *\n",
    "from tensorflow.keras.layers import *\n",
    "\n",
    "from tensorflow.keras.callbacks import *\n",
    "from tensorflow.keras.optimizers import *\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score\n",
    "\n",
    "import math\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "74b8ce4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(cm, classes, title='Confusion matrix', cmap=plt.cm.Blues):\n",
    "\n",
    "    cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title, fontsize=25)\n",
    "    #plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=90, fontsize=15)\n",
    "    plt.yticks(tick_marks, classes, fontsize=15)\n",
    "\n",
    "    fmt = '.2f'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\", fontsize = 14)\n",
    "\n",
    "    plt.ylabel('True label', fontsize=20)\n",
    "    plt.xlabel('Predicted label', fontsize=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bfccd608",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.appName(\"OC-CNN\").getOrCreate()\n",
    "spark.conf.set('spark.sql.caseSensitive', True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f836ff4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepareData():\n",
    "    df_list= []\n",
    "\n",
    "    for root,subdir,files in os.walk(\"C:/Users/aweso/Downloads/RansomWareLZ0321/\"):\n",
    "        if len(files)>0:\n",
    "            for file in files:\n",
    "                if len(file.split(\".\"))>1 and file.split('.')[-1] == \"json\":\n",
    "                    filePath = \"/\".join((root,file))\n",
    "                    df = spark.read.format(\"json\").option(\"inferSchema\",True).load(filePath).drop(\"type\").toPandas()\n",
    "                    # Get one hot encoding of columns B\n",
    "    #                 one_hot = pd.get_dummies(df['type'])\n",
    "    #                 # Drop column B as it is now encoded\n",
    "    #                 df = df.drop('type',axis = 1)\n",
    "    #                 df = df.join(one_hot).groupby('eventid').max()\n",
    "                    df_list.append(df)\n",
    "\n",
    "    return pd.concat(df_list)\n",
    "\n",
    "import math\n",
    "def datagen(data, kind):\n",
    "#     \"As a generator to produce samples for Keras model\"\n",
    "    batch = []\n",
    "    for j in range(10,len(data)-1,10):\n",
    "        # Pick one dataframe from the pool\n",
    "        if kind==\"train\":\n",
    "            if (j//10)%10<7:\n",
    "#                 print(type())\n",
    "                df = data[j-10:j]\n",
    "                df = df.values\n",
    "                if(not math.isnan(df.sum())):\n",
    "                    batch.append(df)\n",
    "        else:\n",
    "            if (j//10)%10>=7:\n",
    "                df = data[j-10:j].values\n",
    "                if(not math.isnan(df.sum())):\n",
    "                    batch.append(df)\n",
    "            \n",
    "    return batch\n",
    "\n",
    "def datagenBenign(filePath):\n",
    "    # read benign data\n",
    "    batch = []\n",
    "    data = spark.read.format(\"json\").option(\"inferSchema\",True).load(filePath).toPandas()\n",
    "    for j in range(10,len(data)-1,10):\n",
    "        batch.append(data[j-10:j].values)\n",
    "        \n",
    "    return np.asanyarray(batch)\n",
    "    \n",
    "\n",
    "# Process all malware samples\n",
    "bigDF =prepareData()\n",
    "# Batch them by 10 event id sequences\n",
    "train = np.array(datagen(bigDF,\"train\"))\n",
    "trainy= np.array([np.array([np.repeat(1.0,10).reshape((-1,1)),np.repeat(0.0,10).reshape((-1,1))]) for i in range(0,train.shape[0])])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6ea75c1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Batch malware samples for testing\n",
    "test_mal = np.array(datagen(bigDF,\"test\"))[0:185]\n",
    "mal_test_labels = np.array([np.repeat(1.0,10).reshape((-1,1)) for i in range(0,test_mal.shape[0])])\n",
    "# Load benign data in\n",
    "test_benign = datagenBenign(\"C:/Users/aweso/Downloads/BenignLZ2/part-00000-e640bdac-daa9-4bd4-be6a-889214dcf4e5-c000.json\")\n",
    "benign_test_labels = np.array([np.repeat(0.0,10).reshape((-1,1)) for i in range(0,test_benign.shape[0])])\n",
    "\n",
    "# Concatenate the data for testing\n",
    "test_data = np.concatenate([test_mal,test_benign])\n",
    "test_labels = np.concatenate([mal_test_labels,benign_test_labels])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d432c66e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(369, 10, 45)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print(benign_test_labels.shape)\n",
    "# print(test_labels.shape)\n",
    "test_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "33a3157b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 10, 45)]     0           []                               \n",
      "                                                                                                  \n",
      " lambda (Lambda)                (None, 10, 45)       0           ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " gaussian_noise (GaussianNoise)  (None, 10, 45)      0           ['lambda[0][0]']                 \n",
      "                                                                                                  \n",
      " lambda_1 (Lambda)              (None, 10, 45)       0           ['input_1[0][0]',                \n",
      "                                                                  'gaussian_noise[0][0]']         \n",
      "                                                                                                  \n",
      " activation (Activation)        (None, 10, 45)       0           ['lambda_1[0][0]']               \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 10, 100)      4600        ['activation[0][0]']             \n",
      "                                                                                                  \n",
      " dense_1 (Dense)                (None, 10, 50)       5050        ['dense[0][0]']                  \n",
      "                                                                                                  \n",
      " dense_2 (Dense)                (None, 10, 1)        51          ['dense_1[0][0]']                \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 9,701\n",
      "Trainable params: 9,701\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "SHAPE = (10,45)\n",
    "\n",
    "def get_model(train=True):\n",
    "    initTensor = Input(SHAPE)\n",
    "    noise = Lambda(tf.zeros_like)(initTensor)\n",
    "    noise = GaussianNoise(0.01)(noise)\n",
    "    if train:\n",
    "        x = Lambda(lambda z: tf.concat(z,axis=0))([initTensor,noise])\n",
    "        x = Activation('relu')(x)\n",
    "    else:\n",
    "        x= initTensor\n",
    "    \n",
    "    x = Dense(100,activation='relu')(x)\n",
    "    x = Dense(50,activation='relu')(x)\n",
    "    out = Dense(1,activation='sigmoid')(x)\n",
    "    \n",
    "    mdl = Model(initTensor,out)\n",
    "#     mdl.compile(loss=['binary_crossentropy','binary_crossentropy'],\n",
    "#                 optimizer='adam'\n",
    "#     )\n",
    "    \n",
    "    return mdl\n",
    "    \n",
    "\n",
    "model = get_model(True)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3319cfe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "\n",
    "def get_model(type):\n",
    "    # reload network weights\n",
    "    if (type == 'ransomware'):\n",
    "        path = 'ransomware_0321_wellrounded/'\n",
    "    else:\n",
    "        path = 'model/model_weights/trojan/'\n",
    "    model = keras.models.load_model(path)\n",
    "    return model\n",
    "\n",
    "def predict(model,data):\n",
    "    preds = model.predict(data)\n",
    "    return preds, np.round(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5ec5685d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n",
      "Model: \"model_25\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_26 (InputLayer)       [(None, 10, 45)]          0         \n",
      "                                                                 \n",
      " dense_75 (Dense)            (None, 10, 100)           4600      \n",
      "                                                                 \n",
      " dense_76 (Dense)            (None, 10, 50)            5050      \n",
      "                                                                 \n",
      " dense_77 (Dense)            (None, 10, 1)             51        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 9,701\n",
      "Trainable params: 9,701\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "mdl = get_model('ransomware')\n",
    "mdl.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "fa7b90d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 10, 45)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test =test_data[0:3]\n",
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "109593b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "cs,pred = predict(model,test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "5ff19396",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30, 45)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.reshape(test.shape[0]*test.shape[1],test.shape[2]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9db47ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate an optimizer to train the model.\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=1e-5)\n",
    "# Instantiate a loss function.\n",
    "loss_fn = tf.keras.losses.BinaryCrossentropy()\n",
    "\n",
    "# Prepare the metrics.\n",
    "train_acc_metric = tf.keras.metrics.BinaryAccuracy()\n",
    "# val_acc_metric = keras.metrics.SparseCategoricalAccuracy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4580e3f8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import time\n",
    "#TRAINING\n",
    "model = get_model(True)\n",
    "\n",
    "#Number of epochs set to run\n",
    "epochs = 5\n",
    "batch_size=1\n",
    "seed=4\n",
    "tf.random.set_seed(seed)\n",
    "4\n",
    "#Early stopping (disabled by default)\n",
    "# Threshold for training loss\n",
    "es=True;\n",
    "earlystop_thresh=1e-6;\n",
    "\n",
    "flag = False;\n",
    "for epoch in range(epochs):\n",
    "    print(\"\\nStart of epoch %d\" % (epoch,))\n",
    "    start_time = time.time()\n",
    "    \n",
    "    prev_loss=0.0\n",
    "    # Iterate over the batches of the dataset.\n",
    "    for i in range(0,train.shape[0]):\n",
    "        x_batch_train=np.expand_dims(train[i],0)\n",
    "        y_batch_train=trainy[i]\n",
    "        with tf.GradientTape() as tape:\n",
    "            logits = model(x_batch_train, training=True)\n",
    "            loss_value = loss_fn(y_batch_train, logits)\n",
    "            \n",
    "            if (abs(loss_value.numpy()-prev_loss)< earlystop_thresh and es == True):\n",
    "                flag=True\n",
    "                break;\n",
    "            \n",
    " \n",
    "            grads = tape.gradient(loss_value, model.trainable_weights)\n",
    "            optimizer.apply_gradients(zip(grads, model.trainable_weights))\n",
    "\n",
    "            # Update training metric.\n",
    "            train_acc_metric.update_state(y_batch_train, logits)\n",
    "\n",
    "        # Log every 200 batches.\n",
    "        if i % 200 == 0:\n",
    "            prev_loss = loss_value.numpy()\n",
    "            print(\n",
    "                \"Training loss (for one batch) at step %d: %.4f\"\n",
    "                % (i, float(loss_value))\n",
    "            )\n",
    "            print(\"Seen so far: %d samples\" % ((i + 1) * batch_size))\n",
    "            \n",
    "    if flag == True:\n",
    "        print(\"\\nStopped on %d\" % (epoch,))\n",
    "        print(\"Loss below threshold\")\n",
    "        break;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf9e17b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "## SWITCH TO INFERENCE FOR COMPUTING PREDICTIONS\n",
    "## (TURN OFF CONCATENATION)\n",
    "inference_mdl = get_model(train=False)\n",
    "inference_mdl.set_weights(model.get_weights(''))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dab91417",
   "metadata": {},
   "outputs": [],
   "source": [
    "inference_mdl = keras.models.load_model('ransomware_0321_3rdtime/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62aa1ca4",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_test = (inference_mdl.predict(test_data))\n",
    "rounded = np.round(pred_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "774d47d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Accuracy: ',accuracy_score(np.concatenate(test_labels),np.concatenate(rounded)))\n",
    "print('Precision: ',precision_score(np.concatenate(test_labels),np.concatenate(rounded)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fded93ee",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cnf_matrix = confusion_matrix(np.concatenate(test_labels), np.concatenate(rounded))\n",
    "plt.figure(figsize=(7,7))\n",
    "plot_confusion_matrix(cnf_matrix, classes=['not Mal','Mal'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "135b52c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "inference_mdl.save(\"trojan\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
