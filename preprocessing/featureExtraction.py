from pyspark.sql.window import Window
import pyspark.sql.functions as fn
import sys
import os


def sourcedDf(df):
    cols = ["@timestamp"]

    # think of bringing in type

    res = (df
           .withColumn("parentpid_present", fn.when(fn.col("process.parent.pid").isNotNull(), 1).otherwise(0))
           .withColumn("parentexe_present",
                       fn.when(fn.col("process.parent.executable").isNotNull(), 1).otherwise(0))
           .withColumn("eventid", fn.monotonically_increasing_id() + 1)
           .withColumn('timestamp', fn.to_utc_timestamp(fn.col("@timestamp").cast('timestamp'),'UTC'))
           .drop("@timestamp")
           .orderBy("timestamp")
           )

    return res


def rollingWindowCount(df, cde, lag):
    w = (Window
         .orderBy("timestamp")
         .rowsBetween(-(lag), 0)
         )
    res = (df
           .withColumn(str(cde) + "orNot", fn.when(fn.col("winlog.event_id") == cde, 1).otherwise(0))
           .withColumn(str(cde) + "_eventwindow",
                       fn.sum(str(cde) + "orNot")
                       .over(w))
           .drop(str(cde) + "orNot"))

    return res


# lag in minutes
def rollingWindowTime(df, cde, time):
    tmp = df.withColumn("timeinmilli",
                        (fn.to_timestamp(fn.col("timestamp")).cast("double") * 1000).cast('long'))

    #               ???  * sec
    lag = lambda i: 1000 * 1 * i
    w = (Window
         .orderBy(fn.asc("timeinmilli"))
         .rangeBetween(-lag(time), 0))

    res = tmp \
        .withColumn("code_flag", fn.when(fn.col("winlog.event_id") == cde, 1).otherwise(0)) \
        .withColumn("eventid_" + str(cde) + "_timewindowcount", fn.sum(fn.col("code_flag")).over(w)) \
        .drop("timeinmilli", "code_flag")

    return res


def previousTimeCreation(df):
    if df.filter(fn.col("winlog.event_id") == 2).count() == 0:
        return df.withColumn("timebetweenfilechange_eventid_2", fn.lit(-1.00))

    res = (df
           .withColumn('newcreationtime', fn.when(df.winlog.event_id == 2, fn.to_timestamp(
        fn.col('winlog.event_data.CreationUtcTime')).cast('double')).otherwise(fn.lit(0.00)))
           .withColumn('previouscreationtime', fn.when(df.winlog.event_id == 2, fn.to_timestamp(
        fn.col('winlog.event_data.PreviousCreationUtcTime')).cast('double')).otherwise(fn.lit(0.00)))
           )

    fin = (res.withColumn("timebetweenfilechange_eventid_2",
                          (res.previouscreationtime * 1000).cast('long') - (res.newcreationtime * 1000).cast('long'))
           .drop('newcreationtime', 'previouscreationtime'))
    return fin


def badCount(df):
    words = ["fail", "tried", "invalid"]

    tmp = (df
           .withColumn("message", fn.col("message"))
           .withColumn("failPresent", fn.when(fn.lower(fn.col("message")).contains(words[0]), 1).otherwise(0))
           .withColumn("triedPresent", fn.when(fn.lower(fn.col("message")).contains(words[1]), 1).otherwise(0))
           .withColumn("invalidPresent",
                       fn.when(fn.lower(fn.col("message")).contains(words[2]), 1).otherwise(0))
           )
    return tmp


def processdf(df, type):
    source = df.transform(sourcedDf)
    sysmon_range = [i for i in range(1, 26)]

    if type == 'ransomware':
        res = (source
               # doing sequential id counts
               .transform(lambda df: rollingWindowCount(df, 1, 100))
               .transform(lambda df: rollingWindowCount(df, 6, 100))
               .transform(lambda df: rollingWindowCount(df, 7, 100))
               .transform(lambda df: rollingWindowCount(df, 8, 100))
               .transform(lambda df: rollingWindowCount(df, 11, 100))
               .transform(lambda df: rollingWindowCount(df, 12, 100))
               .transform(lambda df: rollingWindowCount(df, 13, 100))
               .transform(lambda df: rollingWindowCount(df, 16, 100))

               # presence of bad key-words
               .transform(lambda df: badCount(df))

               # time-window peak back
               .transform(lambda df: rollingWindowTime(df, 1, 30))
               .transform(lambda df: rollingWindowTime(df, 6, 30))
               .transform(lambda df: rollingWindowTime(df, 7, 30))
               .transform(lambda df: rollingWindowTime(df, 8, 30))
               .transform(lambda df: rollingWindowTime(df, 11, 30))
               .transform(lambda df: rollingWindowTime(df, 12, 30))
               .transform(lambda df: rollingWindowTime(df, 13, 30))
               .transform(lambda df: rollingWindowTime(df, 16, 30))
               )
    elif type == 'trojan':
            res = (source
                   # doing sequential id counts
                   .transform(lambda df: rollingWindowCount(df, 1, 100))
                   .transform(lambda df: rollingWindowCount(df, 3, 100))
                   .transform(lambda df: rollingWindowCount(df, 11, 100))
                   .transform(lambda df: rollingWindowCount(df, 12, 100))
                   .transform(lambda df: rollingWindowCount(df, 16, 100))
                   .transform(lambda df: rollingWindowCount(df, 22, 100))
                   .transform(lambda df: rollingWindowCount(df, 24, 100))

                   # presence of bad key-words
                   .transform(lambda df: badCount(df))

                   # time-window peak back
                   .transform(lambda df: rollingWindowTime(df, 1, 30))
                   .transform(lambda df: rollingWindowTime(df, 3, 30))
                   .transform(lambda df: rollingWindowTime(df, 11, 30))
                   .transform(lambda df: rollingWindowTime(df, 12, 30))
                   .transform(lambda df: rollingWindowTime(df, 16, 30))
                   .transform(lambda df: rollingWindowTime(df, 22, 30))
                   .transform(lambda df: rollingWindowTime(df, 24, 30))
                   )
    else:
        res = (source
               # doing sequential id counts
               .transform(lambda df: rollingWindowCount(df, 2, 100))
               .transform(lambda df: rollingWindowCount(df, 11, 100))
               .transform(lambda df: rollingWindowCount(df, 13, 100))
               .transform(lambda df: rollingWindowCount(df, 16, 100))
               .transform(lambda df: rollingWindowCount(df, 22, 100))

               # presence of bad key-words
               .transform(lambda df: badCount(df))

               # time-window peak back
               .transform(lambda df: rollingWindowTime(df, 2, 30))
               .transform(lambda df: rollingWindowTime(df, 11, 30))
               .transform(lambda df: rollingWindowTime(df, 13, 30))
               .transform(lambda df: rollingWindowTime(df, 16, 30))
               .transform(lambda df: rollingWindowTime(df, 22, 30))
               )

    res = (res
           # if file creation time change, record time between changes
           .transform(lambda df: previousTimeCreation(df))
           .filter(fn.col("winlog.event_id").cast("int").isin(sysmon_range))
           .drop("message", "process", "winlog", "eventid")
           )
    return res
